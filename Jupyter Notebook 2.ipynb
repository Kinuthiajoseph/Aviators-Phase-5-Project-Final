{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X (Twitter) Sentiment Analyis for Top Airlines in the USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 8 - Aviators. Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Joseph Kinuthia (Group leader)\n",
    "2. Emily Owiti\n",
    "3. James Mungai\n",
    "4. Paul Muriithi\n",
    "5. Raphael Kariuki\n",
    "6. Sylvia Muchiri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we focus on leveraging Natural Language Processing (NLP) techniques to analyze sentiments expressed in a Twitter dataset, specifically within the airline industry domain. The primary objectives include sentiment analysis, the construction of a precise tweet classification model, and the development of a chatbot capable of responding to customer feedback and directing queries to the appropriate resolution teams. By accomplishing these goals, we will create solutions that enable airline companies to extract valuable insights from social media data which will play a big role in enhancing their customer service, improving their service offering and empowering these organizations to make data-driven decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advent of social media has generated an abundance of data, presenting both opportunities and challenges for organizations. This vast pool of data offers unparalleled insights into customer perceptions, preferences, and feedback. However, many organizations are yet to develop frameworks and strategies to effectively analyze and interpret such data. Insights from this data holds the potential to benefit various domains, including business operations, marketing strategies, public opinion analysis, and more.\n",
    "\n",
    "Our stakeholders (top American airline companies) have requested us to analyze social media raw data and showcase the customer sentiment as either positive, neutral or negative while identifying the top drivers for these sentiments.\n",
    "\n",
    "Our dataset is sourced from Twitter, capturing a wide array of tweets, and our primary focus is analyzing and visualizing drivers for key & top public & customer sentiment. We aim to address critical questions and challenges faced by airlines, such as understanding passenger sentiments from unstructured data and predicting engagement metrics. By doing so, we strive to provide airlines with the tools and knowledge needed to enhance customer experiences, optimize operations, and make data-driven decisions in an ever-evolving and competitive industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Business understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset includes data for the top 5 airline companies in the USA and these are our primary stakeholders for the project. The key players are United Airlines, US Airways, American Airlines, Delta Airlines and Southwest Airlines.\n",
    "\n",
    "Below we discuss the general trends and factors that are common in the global airline industry.\n",
    "\n",
    "The global airline industry is a vital sector that provides air transport services for passengers and cargo. It plays a crucial role in connecting people, businesses, and regions across the world. The industry comprises a diverse range of airlines, including full-service carriers, low-cost carriers (LCCs), regional airlines, and charter airlines. Major players are often categorized into international, national, and regional carriers, each serving specific markets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global airline industry trends:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trends below were useful in developing our understanding and hence optimal analysis our dataset.\n",
    "\n",
    "1. Digital transformation and technology adoption:\n",
    "While late adopters, airlines are increasingly leveraging technology to enhance operational efficiency, customer experiences, and overall service quality. This includes implementing mobile apps, self-service kiosks, AI-powered chatbots, and data analytics for personalized marketing and improved decision-making.\n",
    "\n",
    "2. Sustainable and environmentally friendly practices:\n",
    "Environmental sustainability has become a significant focus within the industry. Airlines are investing in more fuel-efficient aircraft, exploring biofuels, and implementing eco-friendly practices to reduce carbon emissions and mitigate their environmental impact.\n",
    "\n",
    "3. Demand for personalized travel experiences:\n",
    "Travelers now seek personalized experiences, leading to a shift in airline strategies. Airlines are customizing services, offering ancillary products, and tailoring loyalty programs to meet individual preferences and needs.\n",
    "\n",
    "4. Partnerships and alliances:\n",
    "Collaborations, partnerships, and alliances among airlines have become prevalent. These agreements help airlines expand their networks, improve cost-efficiency, and offer travelers more seamless travel options.\n",
    "\n",
    "5. Health and safety measures post-pandemic:\n",
    "The COVID-19 pandemic has significantly impacted the industry. Airlines are implementing stringent health and safety protocols to regain traveler confidence. Measures include enhanced cleaning procedures, health screenings, and contactless processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airline industry profit margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The net profit margin for airlines is highly influenced by market conditions, fuel prices, operational efficiency, competition, and economic trends. On average, net profit margins for airlines typically range from 2% to 5%. However, it's important to note that individual airline net profit margins may fluctuate, and some airlines may experience periods of losses due to various factors affecting the industry. Airlines with a positive brand tend to have lower customer churn and in return higher pricing and higher revenues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Project objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Main objective\n",
    "1. Sentiment analysis and chatbot development\n",
    "2. Come up with a solution to analyze raw tweets to extract the public sentiment ******** review this *****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Specific objectives\n",
    "1. Analyze the data & derive the public's sentiment (positive, neutral or negative) for our client\n",
    "2. Build a model that can classify raw tweets into the three sentiment classes for future use\n",
    "3. Visualize the top drivers for each sentiment category to help management target service delivery improvement\n",
    "4. Create a chatbot to monitor customer feedback on X that provides realtime responses to customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Research questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project will be answer the below research questions:\n",
    "1. What are the predominant sentiments expressed by passengers on X regarding major U.S. airlines?\n",
    "2. What are the most common reasons for positive, neutral and negative sentiments among airline passengers, as expressed in their tweets?\n",
    "3. Are there specific times of the year when sentiment toward airlines is more positive or negative?\n",
    "4. How does the sentiment compare between the various airlines in our dataset (highest positive, negative, neutral)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset was publicly sourced from crowdflower website and is made up of Twitter users' tweets and retweets.\n",
    "The dataset has 14,640 rows and 20 columns.\n",
    "This Twitter data was collected from February 2015 and contributors were engaged in classifying tweets into categories of positive, negative, and neutral sentiments. Additionally, contributors were tasked with categorizing the reasons behind negative sentiments, such as \"late flight\" or \"rude service.\"\n",
    "\n",
    "This dataset serves as the foundation for our analysis, enabling us to gain insights into passenger & general public sentiments, engagement patterns, and other trends within the US airline industry.\n",
    "\n",
    "[Link to the Data Source](https://data.world/crowdflower/airline-twitter-sentiment/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 Project approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploratory data analysis & data cleaning (including categorical variable encoding, feature engineering)\n",
    "2. Data preprocessing for NLP (preparing text for sentiment scoring)\n",
    "3. Data labelling & determining labelling accuracy\n",
    "3. Sentiment analysis\n",
    "4. Visualization of sentiment analysis outcomes\n",
    "5. Prediction model building & validation\n",
    "6. Chatbot development\n",
    "7. Prediction model & chatbot deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our project objectives are as follows:\n",
    "1. Data Acquisition and Exploration:\n",
    "\n",
    "* We will begin by importing and loading the new dataset into our data analysis environment (e.g., Python using pandas).\n",
    "* Conduct an initial exploration of the data to understand its structure, column names, and data types.\n",
    "* Check for missing values and handle them appropriately through imputation or removal.\n",
    "\n",
    "2. Data Preprocessing:\n",
    "\n",
    "* Preprocess the data to prepare it for analysis. This includes tasks such as cleaning text data, encoding categorical variables, and feature engineering.\n",
    "For sentiment analysis, prepare the \"text\" column for sentiment scoring using NLP techniques or pre-trained sentiment analysis models.\n",
    "\n",
    "3. Sentiment Analysis:\n",
    " \n",
    "* To address the first objective of determining the overall sentiment distribution in the tweets, we will perform sentiment analysis on the \"text\" column using Natural Language Processing (NLP) techniques or pre-trained sentiment analysis models. These methods will categorize tweets into positive, negative, or neutral sentiment categories for validation or additional insights.\n",
    "* Visualize the sentiment distribution using bar charts or pie charts to illustrate the prevalence of each sentiment category in the dataset. For instance, we will analyze whether sentiment tends to be more positive on certain days or during specific hours.\n",
    "  \n",
    "4. Location Analysis:\n",
    "\n",
    "* Investigate correlations between language, geographical location, and sentiment using statistical tests and visualizations.\n",
    "* Discover regional sentiment patterns by grouping the data by geographical location and visualizing regional sentiment variations.\n",
    "\n",
    "5. Engagement Prediction:\n",
    "\n",
    "\n",
    "* We will build an effective predictive model for estimating the number of retweets and likes using machine learning techniques. There is a need to preprocess the \"text\" column to extract relevant features, perform text vectorization (e.g., TF-IDF or word embeddings), and incorporate user-related features from the dataset.\n",
    "* Split the dataset into training and testing sets, and train regression models such as Logistic Regression, Random Forest, or Gradient Boosting to predict tweet engagement metrics.\n",
    "  \n",
    "* After developing the predictive model, assess the feature importance to identify which specific features contribute the most to the prediction of tweet engagement (e.g., content-related features, user-related features).\n",
    "* Visualize the feature importance scores using bar charts or feature importance plots to highlight the influential factors.\n",
    "\n",
    "\n",
    "## Modeling\n",
    "\n",
    "For engagement prediction, we will build predictive models using the following steps:\n",
    "\n",
    "**Data Splitting:**\n",
    "   - Split the dataset into training and testing sets to evaluate model performance. We will also use a validation set (or cross-validation) in addition to a training set is to fine-tune model hyperparameters, assess model performance on unseen data, and avoid overfitting. \n",
    "\n",
    "**Regression Models:**\n",
    "   - Train and evaluate various regression models, including but not limited to:\n",
    "     - Logistic Regression\n",
    "     - Random Forest Regression\n",
    "     - Gradient Boosting Regression\n",
    "     - Support Vector Regression\n",
    "     - Neural Network Regression \n",
    "\n",
    "**Model Evaluation:**\n",
    "   - Evaluate the performance of each model using appropriate metrics such as:\n",
    "     - Mean Absolute Error (MAE)\n",
    "      By noting the average absolute error between the predicted engagement metrics (e.g., retweets   or likes) and the actual engagement metrics, we can have a straightforward measure of how far off our predictions are on average.\n",
    "\n",
    "     - Root Mean Square Error (RMSE): Lower RMSE values indicate better performance.\n",
    "  \n",
    "     - R-squared (R2) for goodness of fit\n",
    "      A higher R2 indicates a better fit, meaning that our features are better at explaining the variance in engagement.\n",
    "\n",
    "     - Cross-validation to assess model generalization\n",
    "      cross-validation scores (e.g., cross-validated MAE, RMSE, or R2) to assess how well your model generalizes to unseen data.\n",
    "\n",
    "     - Additional Metrics:\n",
    "      While these metrics provide valuable insights into our model's performance, it's essential to consider the accuracy of our sentiment analysis models as a fundamental measure. Accuracy measures the overall correctness of our model's predictions in classifying tweets into sentiment categories: positive, negative, or neutral.\n",
    "\n",
    "      For a deployable model, we aim to achieve an accuracy score within the range of 90% to 95%. This level of accuracy signifies a high degree of correctness in our predictions and is a strong indicator of the model's reliability in real-world applications.\n",
    "\n",
    "      Also we will consider other metrics, such as precision, recall, or F1-score, to evaluate the model's performance in more detail. \n",
    "\n",
    "**Hyperparameter Tuning:**\n",
    "   - Fine-tune the hyperparameters of the best-performing models using techniques like grid search or random search.\n",
    "\n",
    "**Ensemble Modeling:**\n",
    "   - Consider ensemble methods such as stacking or bagging to improve predictive accuracy.\n",
    "\n",
    "**Model Selection:**\n",
    "   - Select the model(s) that demonstrate the best performance on the evaluation metrics.\n",
    "\n",
    "\n",
    "## Chatbot Development\n",
    "* It will deploy NLP Factors into it to Create separate response templates or messages for positive, negative, and neutral sentiments. These can be predefined messages or more dynamic responses generated by the chatbot. Sentiment-Based Routing:\n",
    "\n",
    "* Develop a logic for routing tweets to the appropriate response based on their sentiment. You can use if-else conditions or switch statements for this purpose.\n",
    "  \n",
    "* For example, if a tweet is classified as \"positive,\" the chatbot responds with a message designed to encourage positive sentiment, while a \"negative\" tweet may receive a message that expresses empathy and offers assistance. For \"neutral\" tweets, you can provide a generic acknowledgment.\n",
    "\n",
    "## Natural Language Understanding (NLU)\n",
    "\n",
    "* Implement natural language understanding to extract key information or context from user tweets. This can help the chatbot provide more relevant and personalized responses.\n",
    "* Use NLU to understand the user's request or sentiment more deeply. For instance, if a user expresses frustration about a delayed flight, the chatbot can identify the issue and respond accordingly.\n",
    "\n",
    "### Testing and Training \n",
    "\n",
    "* Train your chatbot using your predefined response templates and a diverse set of sample tweets to ensure it responds appropriately to different expressions of sentiment.\n",
    "  \n",
    "* Test the chatbot rigorously to identify and correct any issues or inaccuracies in sentiment classification and response generation.\n",
    "\n",
    "### Integration with User Interface\n",
    "\n",
    "* Integrate the chatbot into our API and user interface, whether it's a web application.\n",
    "* Implement a user-friendly interface for users to input their tweets or questions to the chatbot.\n",
    "\n",
    "### Scale and Deploy\n",
    "\n",
    "Once you are satisfied with the chatbot's performance, deploy it ensuring it can handle large volumes of data.\n",
    "\n",
    "* For model deployment, we've chosen to employ Pickle due to its simplicity and efficiency. Once our NLP data science project is complete and our models are trained, we'll serialize these models into Pickle files. \n",
    "  \n",
    "* This serialization process ensures that the models can be easily transferred and loaded into production environments. With Pickle, making predictions on new data becomes a straightforward task, allowing for seamless integration into the airline company's operations.\n",
    "\n",
    "## Scaling for Other Airlines:\n",
    "* Our project isn't limited to just one airline; it can be readily scaled for use by multiple airlines. This scalability stems from the project's customization capabilities. Each airline can tailor the sentiment analysis and engagement prediction models to suit their unique brand and customer base, ensuring that insights generated are highly relevant. \n",
    "  \n",
    "* Airlines can integrate their own customer feedback and social media data into the project, thus benefiting from the same advanced sentiment analysis and engagement prediction features. This collaborative approach promotes industry-wide improvements in customer engagement and satisfaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Importing Necessary Libraries\n",
    "# data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Natural language processing (NLP)\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Deep learning imports \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "# Set the style for data visualization\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Airline-Sentiment-2-w-AA.csv\", encoding='latin 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448150</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>5.703060e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448153</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448156</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448158</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448159</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448150    False   finalized                   3      2/25/15 5:24   \n",
       "1  681448153    False   finalized                   3      2/25/15 1:53   \n",
       "2  681448156    False   finalized                   3     2/25/15 10:01   \n",
       "3  681448158    False   finalized                   3      2/25/15 3:05   \n",
       "4  681448159    False   finalized                   3      2/25/15 5:50   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
       "0                        NaN  Virgin America                    NaN   \n",
       "1                     0.0000  Virgin America                    NaN   \n",
       "2                        NaN  Virgin America                    NaN   \n",
       "3                     0.7033  Virgin America                    NaN   \n",
       "4                     1.0000  Virgin America                    NaN   \n",
       "\n",
       "         name negativereason_gold  retweet_count  \\\n",
       "0     cairdin                 NaN              0   \n",
       "1    jnardino                 NaN              0   \n",
       "2  yvonnalynn                 NaN              0   \n",
       "3    jnardino                 NaN              0   \n",
       "4    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "   tweet_created      tweet_id tweet_location               user_timezone  \n",
       "0  2/24/15 11:35  5.703060e+17            NaN  Eastern Time (US & Canada)  \n",
       "1  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "2  2/24/15 11:15  5.703010e+17      Lets Play  Central Time (US & Canada)  \n",
       "3  2/24/15 11:15  5.703010e+17            NaN  Pacific Time (US & Canada)  \n",
       "4  2/24/15 11:14  5.703010e+17            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 20 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   _unit_id                      14640 non-null  int64  \n",
      " 1   _golden                       14640 non-null  bool   \n",
      " 2   _unit_state                   14640 non-null  object \n",
      " 3   _trusted_judgments            14640 non-null  int64  \n",
      " 4   _last_judgment_at             14584 non-null  object \n",
      " 5   airline_sentiment             14640 non-null  object \n",
      " 6   airline_sentiment:confidence  14640 non-null  float64\n",
      " 7   negativereason                9178 non-null   object \n",
      " 8   negativereason:confidence     10522 non-null  float64\n",
      " 9   airline                       14640 non-null  object \n",
      " 10  airline_sentiment_gold        40 non-null     object \n",
      " 11  name                          14640 non-null  object \n",
      " 12  negativereason_gold           32 non-null     object \n",
      " 13  retweet_count                 14640 non-null  int64  \n",
      " 14  text                          14640 non-null  object \n",
      " 15  tweet_coord                   1019 non-null   object \n",
      " 16  tweet_created                 14640 non-null  object \n",
      " 17  tweet_id                      14640 non-null  float64\n",
      " 18  tweet_location                9907 non-null   object \n",
      " 19  user_timezone                 9820 non-null   object \n",
      "dtypes: bool(1), float64(3), int64(3), object(13)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.464000e+04</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>10522.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>1.464000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.814957e+08</td>\n",
       "      <td>3.618648</td>\n",
       "      <td>0.900169</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>5.692184e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.504314e+04</td>\n",
       "      <td>11.858704</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.745778</td>\n",
       "      <td>7.791092e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.814482e+08</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.675880e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.814536e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.685590e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.814578e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.694780e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.814623e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.698902e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.816798e+08</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>5.703110e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _unit_id  _trusted_judgments  airline_sentiment:confidence  \\\n",
       "count  1.464000e+04        14640.000000                  14640.000000   \n",
       "mean   6.814957e+08            3.618648                      0.900169   \n",
       "std    8.504314e+04           11.858704                      0.162830   \n",
       "min    6.814482e+08            2.000000                      0.335000   \n",
       "25%    6.814536e+08            3.000000                      0.692300   \n",
       "50%    6.814578e+08            3.000000                      1.000000   \n",
       "75%    6.814623e+08            3.000000                      1.000000   \n",
       "max    6.816798e+08          248.000000                      1.000000   \n",
       "\n",
       "       negativereason:confidence  retweet_count      tweet_id  \n",
       "count               10522.000000   14640.000000  1.464000e+04  \n",
       "mean                    0.638298       0.082650  5.692184e+17  \n",
       "std                     0.330440       0.745778  7.791092e+14  \n",
       "min                     0.000000       0.000000  5.675880e+17  \n",
       "25%                     0.360600       0.000000  5.685590e+17  \n",
       "50%                     0.670600       0.000000  5.694780e+17  \n",
       "75%                     1.000000       0.000000  5.698902e+17  \n",
       "max                     1.000000      44.000000  5.703110e+17  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The dataset contains 14,640 entries and 20 columns. Here's a brief description of the dataset's contents and the significance of each column:\n",
    "\n",
    "- `_unit_id`: A unique identifier for each data unit.\n",
    "- `_golden`: A boolean value indicating whether the entry is a golden unit in the dataset.\n",
    "- `_unit_state`: The state of the unit (e.g., golden).\n",
    "- `_trusted_judgments`: The number of trusted judgments for the entry.\n",
    "- `_last_judgment_at`: Timestamp of the last judgment for the entry.\n",
    "- `airline_sentiment`: The target variable, which represents the sentiment of the airline tweet (positive, negative, or neutral).\n",
    "- `airline_sentiment:confidence`: The confidence level associated with the airline sentiment.\n",
    "- `negativereason`: The reason for negative sentiment in the tweet.\n",
    "- `negativereason:confidence`: The confidence level associated with the negative sentiment reason.\n",
    "- `airline`: The airline associated with the tweet.\n",
    "- `airline_sentiment_gold`: Additional information about airline sentiment (gold standard).\n",
    "- `name`: The name of the user who posted the tweet.\n",
    "- `negativereason_gold`: Additional information about the negative sentiment reason (gold standard).\n",
    "- `retweet_count`: The number of retweets for the tweet.\n",
    "- `text`: The text content of the tweet.\n",
    "- `tweet_coord`: Coordinates of the tweet (if available).\n",
    "- `tweet_created`: Timestamp of when the tweet was created.\n",
    "- `tweet_id`: The unique identifier of the tweet.\n",
    "- `tweet_location`: The location associated with the tweet (if provided).\n",
    "- `user_timezone`: The timezone of the user who posted the tweet.\n",
    "\n",
    "In this dataset, the `airline_sentiment` column is the target variable, which represents the sentiment of the airline tweet that we may want to predict or analyze. The other columns, such as `text`, `airline`, and `retweet_count`, can be used as features for sentiment analysis, engagement prediction, and language/location analysis.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      @VirginAmerica What @dhepburn said.\n",
      "1        @VirginAmerica plus you've added commercials t...\n",
      "2        @VirginAmerica I didn't today... Must mean I n...\n",
      "3        @VirginAmerica it's really aggressive to blast...\n",
      "4        @VirginAmerica and it's a really big bad thing...\n",
      "                               ...                        \n",
      "14635    @AmericanAir thank you we got on a different f...\n",
      "14636    @AmericanAir leaving over 20 minutes Late Flig...\n",
      "14637    @AmericanAir Please bring American Airlines to...\n",
      "14638    @AmericanAir you have my money, you change my ...\n",
      "14639    @AmericanAir we have 8 ppl so we need 2 know h...\n",
      "Name: text, Length: 14640, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the 'text' column\n",
    "text_column = data['text']\n",
    "print(text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of airlines\n",
    "data['airline'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a countplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.countplot(data=data, x='airline', palette='viridis')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Airline')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Airlines')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**text:** The text content of the tweet is one of the most critical features for sentiment analysis. It contains the actual user-generated content that you can analyze for sentiment.\n",
    "\n",
    "**airline:** The airline associated with the tweet is essential because sentiment can vary depending on the airline. It's a categorical feature that can be one-hot encoded for model training.\n",
    "\n",
    "**negativereason:** If available, the reason for negative sentiment can provide valuable information for understanding why users are expressing negative sentiment towards an airline.\n",
    "\n",
    "**user_timezone:** The timezone of the user who posted the tweet might be relevant because sentiment can vary by geographic region and time of day.\n",
    "\n",
    "**retweet_count:** The number of retweets can be an indicator of the tweet's popularity or how strongly the sentiment is resonating with others. It can serve as a feature to capture engagement.\n",
    "\n",
    "**tweet_location:** The location associated with the tweet might provide insights into regional sentiment variations.\n",
    "\n",
    "**tweet_created:** The timestamp of when the tweet was created can be used for time-based analysis, such as sentiment trends over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unit_id                            0\n",
       "_golden                             0\n",
       "_unit_state                         0\n",
       "_trusted_judgments                  0\n",
       "_last_judgment_at                  56\n",
       "airline_sentiment                   0\n",
       "airline_sentiment:confidence        0\n",
       "negativereason                   5462\n",
       "negativereason:confidence        4118\n",
       "airline                             0\n",
       "airline_sentiment_gold          14600\n",
       "name                                0\n",
       "negativereason_gold             14608\n",
       "retweet_count                       0\n",
       "text                                0\n",
       "tweet_coord                     13621\n",
       "tweet_created                       0\n",
       "tweet_id                            0\n",
       "tweet_location                   4733\n",
       "user_timezone                    4820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals = data.isnull().sum()\n",
    "missing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of relevant features\n",
    "selected_columns = [\"_trusted_judgments\", \"_last_judgment_at\",\n",
    "                    \"airline_sentiment\", \"airline_sentiment:confidence\", \"negativereason\",\n",
    "                    \"negativereason:confidence\", \"airline\", \"retweet_count\", \"text\", \"tweet_created\",\n",
    "                    \"tweet_location\", \"user_timezone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _trusted_judgments _last_judgment_at airline_sentiment  \\\n",
       "0                   3      2/25/15 5:24           neutral   \n",
       "1                   3      2/25/15 1:53          positive   \n",
       "2                   3     2/25/15 10:01           neutral   \n",
       "3                   3      2/25/15 3:05          negative   \n",
       "4                   3      2/25/15 5:50          negative   \n",
       "\n",
       "   airline_sentiment:confidence negativereason  negativereason:confidence  \\\n",
       "0                        1.0000            NaN                        NaN   \n",
       "1                        0.3486            NaN                     0.0000   \n",
       "2                        0.6837            NaN                        NaN   \n",
       "3                        1.0000     Bad Flight                     0.7033   \n",
       "4                        1.0000     Can't Tell                     1.0000   \n",
       "\n",
       "          airline  retweet_count  \\\n",
       "0  Virgin America              0   \n",
       "1  Virgin America              0   \n",
       "2  Virgin America              0   \n",
       "3  Virgin America              0   \n",
       "4  Virgin America              0   \n",
       "\n",
       "                                                text  tweet_created  \\\n",
       "0                @VirginAmerica What @dhepburn said.  2/24/15 11:35   \n",
       "1  @VirginAmerica plus you've added commercials t...  2/24/15 11:15   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  2/24/15 11:15   \n",
       "3  @VirginAmerica it's really aggressive to blast...  2/24/15 11:15   \n",
       "4  @VirginAmerica and it's a really big bad thing...  2/24/15 11:14   \n",
       "\n",
       "  tweet_location               user_timezone  \n",
       "0            NaN  Eastern Time (US & Canada)  \n",
       "1            NaN  Pacific Time (US & Canada)  \n",
       "2      Lets Play  Central Time (US & Canada)  \n",
       "3            NaN  Pacific Time (US & Canada)  \n",
       "4            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[selected_columns]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_trusted_judgments                 0\n",
       "_last_judgment_at                 56\n",
       "airline_sentiment                  0\n",
       "airline_sentiment:confidence       0\n",
       "negativereason                  5462\n",
       "negativereason:confidence       4118\n",
       "airline                            0\n",
       "retweet_count                      0\n",
       "text                               0\n",
       "tweet_created                      0\n",
       "tweet_location                  4733\n",
       "user_timezone                   4820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **_last_judgment_at:**\n",
    "Since _last_judgment_at is a timestamp, we impute missing values with the mode (most frequent) timestamp to maintain the distribution of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_last_judgment_at'].fillna(data['_last_judgment_at'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **negativereason and negativereason:confidence:**\n",
    "These columns are related to the reason for negative sentiment. We impute missing values with a placeholder, \"Not specified\" to indicate that the reason was not provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['negativereason'].fillna('Not specified', inplace=True)\n",
    "data['negativereason:confidence'].fillna('Not specified', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **tweet_location and user_timezone:**\n",
    "These columns represent user-provided data and may be critical for the analysis. We can impute missing values with \"Not Specific\" or \"Unknown\" to indicate that the information was not provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_location'].fillna('Not specified', inplace=True)\n",
    "data['user_timezone'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_trusted_judgments              0\n",
       "_last_judgment_at               0\n",
       "airline_sentiment               0\n",
       "airline_sentiment:confidence    0\n",
       "negativereason                  0\n",
       "negativereason:confidence       0\n",
       "airline                         0\n",
       "retweet_count                   0\n",
       "text                            0\n",
       "tweet_created                   0\n",
       "tweet_location                  0\n",
       "user_timezone                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing \n",
    "NLP, a subset of Data Science, focuses on working with text data. Text data, abundant alongside numerical data, plays a crucial role in solving various business problems. However, before utilizing this data for analysis or predictions, it requires preprocessing.\n",
    "\n",
    "Text preprocessing serves as the initial step in our NLP project and encompasses several key procedures:\n",
    "\n",
    "* Eliminating punctuation marks such as periods, commas, exclamation points, parentheses, asterisks, percentage signs, and at symbols. !#$%&'()*+,-./:;?@[\\]^_`{|}~\n",
    "\n",
    "* Omitting URLs from the text.\n",
    "\n",
    "* Removing common stop words (e.g., \"the,\" \"and,\" \"is\") that do not carry significant meaning.\n",
    "\n",
    "* Converting all text to lowercase for consistency.\n",
    "\n",
    "* Tokenization, breaking the text into individual words or tokens.\n",
    "\n",
    "* Stemming, which reduces words to their root form, often by removing suffixes.\n",
    "\n",
    "* Lemmatization, a more sophisticated technique that reduces words to their base or dictionary form, considering context and meaning.\n",
    "\n",
    "These preprocessing steps help ensure that the text data is clean, structured, and ready for further analysis or modeling in NLP projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal\n",
    "We can see in the below output, all the punctuations are removed from text and stored in the clean_msg column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>VirginAmerica What dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>VirginAmerica plus youve added commercials to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>VirginAmerica I didnt today Must mean I need t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>VirginAmerica its really aggressive to blast o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>VirginAmerica and its a really big bad thing a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _trusted_judgments _last_judgment_at airline_sentiment  \\\n",
       "0                   3      2/25/15 5:24           neutral   \n",
       "1                   3      2/25/15 1:53          positive   \n",
       "2                   3     2/25/15 10:01           neutral   \n",
       "3                   3      2/25/15 3:05          negative   \n",
       "4                   3      2/25/15 5:50          negative   \n",
       "\n",
       "   airline_sentiment:confidence negativereason negativereason:confidence  \\\n",
       "0                        1.0000  Not specified             Not specified   \n",
       "1                        0.3486  Not specified                         0   \n",
       "2                        0.6837  Not specified             Not specified   \n",
       "3                        1.0000     Bad Flight                    0.7033   \n",
       "4                        1.0000     Can't Tell                         1   \n",
       "\n",
       "          airline  retweet_count  \\\n",
       "0  Virgin America              0   \n",
       "1  Virgin America              0   \n",
       "2  Virgin America              0   \n",
       "3  Virgin America              0   \n",
       "4  Virgin America              0   \n",
       "\n",
       "                                                text  tweet_created  \\\n",
       "0                @VirginAmerica What @dhepburn said.  2/24/15 11:35   \n",
       "1  @VirginAmerica plus you've added commercials t...  2/24/15 11:15   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  2/24/15 11:15   \n",
       "3  @VirginAmerica it's really aggressive to blast...  2/24/15 11:15   \n",
       "4  @VirginAmerica and it's a really big bad thing...  2/24/15 11:14   \n",
       "\n",
       "  tweet_location               user_timezone  \\\n",
       "0  Not specified  Eastern Time (US & Canada)   \n",
       "1  Not specified  Pacific Time (US & Canada)   \n",
       "2      Lets Play  Central Time (US & Canada)   \n",
       "3  Not specified  Pacific Time (US & Canada)   \n",
       "4  Not specified  Pacific Time (US & Canada)   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0                   VirginAmerica What dhepburn said  \n",
       "1  VirginAmerica plus youve added commercials to ...  \n",
       "2  VirginAmerica I didnt today Must mean I need t...  \n",
       "3  VirginAmerica its really aggressive to blast o...  \n",
       "4  VirginAmerica and its a really big bad thing a...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#library that contains punctuation\n",
    "import string\n",
    "string.punctuation\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "data['clean_tweet']= data['text'].apply(lambda x:remove_punctuation(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         VirginAmerica What dhepburn said\n",
       "1        VirginAmerica plus youve added commercials to ...\n",
       "2        VirginAmerica I didnt today Must mean I need t...\n",
       "3        VirginAmerica its really aggressive to blast o...\n",
       "4        VirginAmerica and its a really big bad thing a...\n",
       "                               ...                        \n",
       "14635    AmericanAir thank you we got on a different fl...\n",
       "14636    AmericanAir leaving over 20 minutes Late Fligh...\n",
       "14637    AmericanAir Please bring American Airlines to ...\n",
       "14638    AmericanAir you have my money you change my fl...\n",
       "14639    AmericanAir we have 8 ppl so we need 2 know ho...\n",
       "Name: clean_tweet, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowering the Text\n",
    "All the text of clean_msg column are converted into lower case and stored in clean_tweet column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowering text using lambda function\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         virginamerica what dhepburn said\n",
       "1        virginamerica plus youve added commercials to ...\n",
       "2        virginamerica i didnt today must mean i need t...\n",
       "3        virginamerica its really aggressive to blast o...\n",
       "4        virginamerica and its a really big bad thing a...\n",
       "                               ...                        \n",
       "14635    americanair thank you we got on a different fl...\n",
       "14636    americanair leaving over 20 minutes late fligh...\n",
       "14637    americanair please bring american airlines to ...\n",
       "14638    americanair you have my money you change my fl...\n",
       "14639    americanair we have 8 ppl so we need 2 know ho...\n",
       "Name: clean_tweet, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "In this step, the text is split into smaller units. We can use either sentence tokenization or word tokenization based on our problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to tokenize text using a regular expression pattern\n",
    "def tokenize_with_regexp(text):\n",
    "    \n",
    "        # Define the regular expression pattern for tokenization\n",
    "    pattern = r'\\w+|\\$[\\d\\.]+|\\S+'\n",
    "        \n",
    "        # Create a RegexpTokenizer with the pattern\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "        \n",
    "        # Tokenize the text and return the tokens\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "#applying function to the column  \n",
    "data['clean_tweet']= data['clean_tweet'].apply(lambda x: tokenize_with_regexp(x))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [virginamerica, what, dhepburn, said]\n",
       "1        [virginamerica, plus, youve, added, commercial...\n",
       "2        [virginamerica, i, didnt, today, must, mean, i...\n",
       "3        [virginamerica, its, really, aggressive, to, b...\n",
       "4        [virginamerica, and, its, a, really, big, bad,...\n",
       "                               ...                        \n",
       "14635    [americanair, thank, you, we, got, on, a, diff...\n",
       "14636    [americanair, leaving, over, 20, minutes, late...\n",
       "14637    [americanair, please, bring, american, airline...\n",
       "14638    [americanair, you, have, my, money, you, chang...\n",
       "14639    [americanair, we, have, 8, ppl, so, we, need, ...\n",
       "Name: clean_tweet, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the derived Tokens\n",
    "data['clean_tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Word Removal\n",
    "The NLTK library provides a convenient way to access and utilize a list of stopwords for various natural language processing tasks in English. By removing stopwords **[i, me, my, myself, we, our, ours, ourselves]** from text data, we can focus on the more meaningful and context-rich words, which can improve the accuracy and efficiency of text analysis, such as text classification or sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, youve, added, commercial...\n",
       "2    [virginamerica, didnt, today, must, mean, need...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text): \n",
    "    \n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    \n",
    "    return output\n",
    "\n",
    "#applying the function\n",
    "data['clean_tweet']= data['clean_tweet'].apply(lambda x:remove_stopwords(x))\n",
    "data['clean_tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "A process commonly known as \"text standardization,\" involves reducing words to their base or root form. One popular technique for text standardization is \"stemming.\" Stemming involves reducing words to their linguistic stems, which can help in various natural language processing tasks.\n",
    "\n",
    "For instance, consider words like 'programmer,' 'programming,' and 'program.' After stemming, they would all be transformed to 'program.' This process can be beneficial for tasks like information retrieval and text classification, where you want to group related words together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plu, youv, ad, commerci, exper...\n",
       "2    [virginamerica, didnt, today, must, mean, need...\n",
       "3    [virginamerica, realli, aggress, blast, obnoxi...\n",
       "4             [virginamerica, realli, big, bad, thing]\n",
       "Name: msg_stemmed, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the object for stemming\n",
    "porter_stemmer = PorterStemmer() \n",
    "\n",
    "#defining a function for stemming\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text\n",
    "\n",
    "data['msg_stemmed'] =data['clean_tweet'].apply(lambda x: stemming(x))\n",
    "data['msg_stemmed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it's important to note that stemming has its limitations. One significant drawback is that it can sometimes reduce words to a form that loses their original meaning or may not even result in proper English words. For instance, we can see how some words **(really to realli, added to ad in the first third row)** are stemmed to their base, producing base forms that do not conform with standard dictionary. \n",
    "***N/B. lets see how Lemmatization is different from Stemming***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "* Lemmatization, on the other hand, is a more sophisticated approach that involves reducing words to their base or dictionary form (lemma) while considering the context and meaning of the word within the language.\n",
    "* Lemmatization relies on a pre-defined dictionary or vocabulary, which contains information about word meanings and their various forms. It ensures that the resulting word is a valid word in the language.\n",
    "* Lemmatization typically produces more meaningful results compared to stemming. For example, \"running\" would be lemmatized to \"run,\" which is a valid English word.\n",
    "* The difference between Stemming and Lemmatization can be seen in the above output. In the third row- really has been changed to really which remained the same, in-line with standard dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [dhepburn, virginamerica, said]\n",
       "1    [plus, commercial, tacky, youve, added, virgin...\n",
       "2    [trip, must, today, mean, take, didnt, virgina...\n",
       "3    [recourse, obnoxious, guest, really, entertain...\n",
       "4             [really, big, bad, thing, virginamerica]\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization and remove duplicates in text\n",
    "def lemmatizer(text):\n",
    "    \n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    \n",
    "     # Remove duplicates by converting the list to a set and back to a list\n",
    "    lemm_text = list(set(lemm_text))\n",
    "    \n",
    "    return lemm_text\n",
    "\n",
    "data['clean_tweet'] = data['clean_tweet'].apply(lambda x:lemmatizer(x))\n",
    "data['clean_tweet'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unwanted msg_stemmed column\n",
    "data.drop(columns='msg_stemmed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2/24/15 11:35</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>[dhepburn, virginamerica, said]</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:53</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[plus, commercial, tacky, youve, added, virgin...</td>\n",
       "      <td>virginamerica plus youve added commercial expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 10:01</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>[trip, must, today, mean, take, didnt, virgina...</td>\n",
       "      <td>virginamerica didnt today must mean need take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:05</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2/24/15 11:15</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[recourse, obnoxious, guest, really, entertain...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 5:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2/24/15 11:14</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[really, big, bad, thing, virginamerica]</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _trusted_judgments _last_judgment_at airline_sentiment  \\\n",
       "0                   3      2/25/15 5:24           neutral   \n",
       "1                   3      2/25/15 1:53          positive   \n",
       "2                   3     2/25/15 10:01           neutral   \n",
       "3                   3      2/25/15 3:05          negative   \n",
       "4                   3      2/25/15 5:50          negative   \n",
       "\n",
       "   airline_sentiment:confidence negativereason negativereason:confidence  \\\n",
       "0                        1.0000  Not specified             Not specified   \n",
       "1                        0.3486  Not specified                         0   \n",
       "2                        0.6837  Not specified             Not specified   \n",
       "3                        1.0000     Bad Flight                    0.7033   \n",
       "4                        1.0000     Can't Tell                         1   \n",
       "\n",
       "          airline  retweet_count  \\\n",
       "0  Virgin America              0   \n",
       "1  Virgin America              0   \n",
       "2  Virgin America              0   \n",
       "3  Virgin America              0   \n",
       "4  Virgin America              0   \n",
       "\n",
       "                                                text  tweet_created  \\\n",
       "0                @VirginAmerica What @dhepburn said.  2/24/15 11:35   \n",
       "1  @VirginAmerica plus you've added commercials t...  2/24/15 11:15   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  2/24/15 11:15   \n",
       "3  @VirginAmerica it's really aggressive to blast...  2/24/15 11:15   \n",
       "4  @VirginAmerica and it's a really big bad thing...  2/24/15 11:14   \n",
       "\n",
       "  tweet_location               user_timezone  \\\n",
       "0  Not specified  Eastern Time (US & Canada)   \n",
       "1  Not specified  Pacific Time (US & Canada)   \n",
       "2      Lets Play  Central Time (US & Canada)   \n",
       "3  Not specified  Pacific Time (US & Canada)   \n",
       "4  Not specified  Pacific Time (US & Canada)   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0                    [dhepburn, virginamerica, said]   \n",
       "1  [plus, commercial, tacky, youve, added, virgin...   \n",
       "2  [trip, must, today, mean, take, didnt, virgina...   \n",
       "3  [recourse, obnoxious, guest, really, entertain...   \n",
       "4           [really, big, bad, thing, virginamerica]   \n",
       "\n",
       "                                     clean_tweet_str  \n",
       "0                        virginamerica dhepburn said  \n",
       "1  virginamerica plus youve added commercial expe...  \n",
       "2  virginamerica didnt today must mean need take ...  \n",
       "3  virginamerica really aggressive blast obnoxiou...  \n",
       "4                 virginamerica really big bad thing  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words or TF-IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
<<<<<<< HEAD
   "version": "3.8.5"
=======
   "version": "3.10.11"
>>>>>>> 70d0f66a09dea5b11d8d90047a7de16c85db7a8e
=======
   "version": "3.8.5"
>>>>>>> origin/main
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
